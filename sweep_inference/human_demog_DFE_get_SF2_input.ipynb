{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd30ab3d-eef1-4a13-bef7-dd967cf5a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb87ce2-5184-4375-b0a3-2852fa58befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to parse .ms file data into nested list of positions and genotypes\n",
    "#Function takes as input open reading file object and no. of samples\n",
    "def get_nested_data_list(inPath, pop, model, rep, chr_len=198345):\n",
    "    pops = {'AFR':'p1', 'EUR':'p3', 'EAS':'p5', 'SAS':'p4'}\n",
    "    samples = {\"AFR\": 198, \"EUR\": 1004, \"EAS\": 208, \"SAS\": 978}\n",
    "    l_Pos = [] #list of positions of SNPs\n",
    "    l_Genos = [] #list of alleles\n",
    "    d_tmp = {} #dict to store individual allele info for each individual (values) at each site (keys)\n",
    "    \n",
    "    f_ms = open(inPath + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".ms\", 'r')\n",
    "    #positions on line 2\n",
    "    pos_lines = [2]\n",
    "    for position, line in enumerate(f_ms):\n",
    "        if position in pos_lines:\n",
    "            #store positions in list\n",
    "            pos_list  = line.split()\n",
    "    #Set file pointer to start of file\n",
    "    f_ms.seek(0)\n",
    "\n",
    "    i = 0\n",
    "    #Loop through positions, storing in list\n",
    "    for pos in pos_list[1:]:\n",
    "        #Append position to l_Pos (after converting to float)\n",
    "        x = int(np.round(float(pos)*chr_len,0))\n",
    "        l_Pos.append(int(x))\n",
    "        #Add dictionary key for each position, with empty value\n",
    "        d_tmp[str(i)] = \"\"\n",
    "        i += 1  \n",
    "\n",
    "    #genotypes on line 3 onwards (use samples argument to determine length of file)\n",
    "    g_lines = [x for x in range(3, samples[pop] + 4)]\n",
    "    #Loop through lines (ie individuals)\n",
    "    for position, line in enumerate(f_ms):\n",
    "        if position in g_lines:\n",
    "            #Remove newline character\n",
    "            line1 = line.strip('\\n')\n",
    "            i = 0\n",
    "            #For each individual, loop through each site, appending allele information for that individual to \n",
    "            #the site number in dict\n",
    "            while i < len(line1):\n",
    "                d_tmp[str(i)] = d_tmp[str(i)] + line1[i]\n",
    "                i = i + 1\n",
    "\n",
    "    f_ms.seek(0)\n",
    "\n",
    "    #Create nested list of positions and genotypes\n",
    "    l_data = [[j, d_tmp[str(i)]] for i,j in enumerate(l_Pos)]\n",
    "    \n",
    "    #Sum genotype information to get DACs\n",
    "    for i,j in enumerate(l_data):\n",
    "        l_data[i].append(sum([int(x) for x in l_data[i][1]]))\n",
    "    \n",
    "    #Convert dictionary to dataframe, removing genotype column\n",
    "    df = pd.DataFrame(l_data)[[0,2]]\n",
    "    #Rename columns\n",
    "    df.columns = ['position', 'x']\n",
    "    #Add samples info\n",
    "    df['n'] = samples[pop]\n",
    "    #Add fold info\n",
    "    df['folded'] = 0\n",
    "\n",
    "    #Read in .fixed file\n",
    "    fixed = pd.read_csv(inPath + \"/rep\" + str(rep) + \"_model\" + str(model) + \".fixed\", skiprows=2, sep=' ',\n",
    "                   names=['tempID', 'permID', 'mutType', 'position', 's', 'h', 'initial_subpop', 'originTick',\n",
    "                         'fix_gen'])\n",
    "    fixed[(fixed.originTick>=94000)]\n",
    "    fixed = fixed[['position']]\n",
    "    \n",
    "    f = pd.read_csv(inPath + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".fixed\", sep=' ', \n",
    "                names=['OUT', 'tick', 'cycle', 'T', 'subpopID', 'mutID', 'mutType', 'position', 's', 'h', 'originPop', 'originTick', 'AC'])\n",
    "\n",
    "    #Subset for only relevant population and mutations that occur after burnin\n",
    "    f = f[(f.subpopID == pops[pop])& (f.originTick>=94000)]\n",
    "    #Keep only position column\n",
    "    f = f[['position']]\n",
    "\n",
    "    f = pd.concat([fixed,f])\n",
    "    f = f.drop_duplicates()\n",
    "\n",
    "    #Create dataframe of fixed mutations\n",
    "    f_df = pd.DataFrame([[x,samples[pop],samples[pop],0] for x in f.position])\n",
    "    if(len(f_df)>0):\n",
    "        f_df.columns = df.columns\n",
    "        #Concatenate dfs and sort by position\n",
    "        aff = pd.concat([df, f_df]).sort_values('position').reset_index(drop='True')\n",
    "    else:\n",
    "        aff = df.reset_index(drop='True')\n",
    "    #Remove duplicates, keeping the higher value (ie in case the beneficial has overlayed a previous mutation)\n",
    "    aff = aff.groupby('position', group_keys=False).apply(lambda x: x.loc[x['x'].idxmax()], include_groups=False)\n",
    "    aff['position'] = aff.index\n",
    "    aff = aff.reset_index(drop=True)\n",
    "    aff = aff[['position','x','n','folded']]\n",
    "    \n",
    "    return(aff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bdd4b79-cbcb-4c52-845e-32f094a9198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 1\n",
    "for Nes in [1000, 10000]:\n",
    "    for pop in ['AFR', 'EUR', 'EAS', 'SAS']:\n",
    "        for rep in range(1, 101):\n",
    "            df = get_nested_data_list(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/sims/\" + str(Nes), pop, model, rep, chr_len=198345)\n",
    "            df.to_csv(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/SF_files/\" + str(Nes) + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".aff\", \n",
    "                      sep='\\t', header=True, index=False)\n",
    "            df = df[['position']]\n",
    "            df.to_csv(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/SF_files/\" + str(Nes) + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".grid\", \n",
    "                      sep='\\t', header=False, index=False)\n",
    "\n",
    "model = 2\n",
    "for Nes in [1000, 10000]:\n",
    "    for pop in ['EUR', 'EAS', 'SAS']:\n",
    "        for rep in range(1, 101):\n",
    "            df = get_nested_data_list(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/sims/\" + str(Nes), pop, model, rep, chr_len=198345)\n",
    "            df.to_csv(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/SF_files/\" + str(Nes) + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".aff\", \n",
    "                      sep='\\t', header=True, index=False)\n",
    "            df = df[['position']]\n",
    "            df.to_csv(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/SF_files/\" + str(Nes) + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".grid\", \n",
    "                      sep='\\t', header=False, index=False)\n",
    "            \n",
    "model = 3\n",
    "for Nes in [1000, 10000]:\n",
    "    for pop in ['EUR']:\n",
    "        for rep in range(1, 101):\n",
    "            df = get_nested_data_list(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/sims/\" + str(Nes), pop, model, rep, chr_len=198345)\n",
    "            df.to_csv(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/SF_files/\" + str(Nes) + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".aff\", \n",
    "                      sep='\\t', header=True, index=False)\n",
    "            df = df[['position']]\n",
    "            df.to_csv(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/SF_files/\" + str(Nes) + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".grid\", \n",
    "                      sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5113a8d9-d1a2-4946-973a-c2461bf86aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 3\n",
    "for Nes in [1000, 10000]:\n",
    "    for pop in ['EUR']:\n",
    "        for rep in range(1, 101):\n",
    "            f_aff = r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/SF_files/\" + str(Nes) + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".aff\"\n",
    "            f_rec = r\"/home/vsoni11/human_demog_DFE/rr_maps/\" + str(rep) + \".txt\"\n",
    "            #Read in aff file\n",
    "            df = pd.read_csv(f_aff, header=0, sep='\\t')\n",
    "            #Read in rr file\n",
    "            rr = pd.read_csv(f_rec, names=['pos','ro'], sep='\\t')\n",
    "            \n",
    "            #Create nested list of ro at each position\n",
    "            l = [[x*10**-6] * 10000 for x in rr.ro]\n",
    "            #Flattern nested list\n",
    "            lst = [item for sublist in l for item in sublist]\n",
    "            \n",
    "            #Create list for results, starting with a 0\n",
    "            res = [0]\n",
    "            #Loop through positions\n",
    "            for i in range(0, len(df.position)-1):\n",
    "                #Set indexes to calculate sum of rates between polymorphisms\n",
    "                p2 = df.position[i]\n",
    "                p1 = df.position[i+1] \n",
    "                res.append(np.sum(lst[p2:p1]))\n",
    "            \n",
    "            df['rate'] = res\n",
    "            df = df[['position', 'rate']]\n",
    "            df.to_csv(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/SF_files/\" + str(Nes) + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".rec\", \n",
    "                      sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a1606c2-e879-420f-83e2-dc026f8fc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Nes in [100, 1000, 10000]:\n",
    "    for pop in ['AFR', 'EUR', 'EAS', 'SAS']:\n",
    "        for model in range(1, 4):\n",
    "            df = pd.DataFrame()\n",
    "            for rep in range(1, 101):\n",
    "                f_aff = r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/SF_files/\" + str(Nes) + \"/\" + pop + \"_rep\" + str(rep) + \"_model\" + str(model) + \".aff\"\n",
    "                fdf = pd.read_csv(f_aff, header=0, sep='\\t')\n",
    "                df = pd.concat([df, fdf])\n",
    "            df.to_csv(r\"/ospool/ap21/data/vsoni11/hdd_res/sweep_detection/singleSweep/SF_files/\" + str(Nes) + \"/\" + pop + \"_model\" + str(model) + \"_all.aff\", \n",
    "                      sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f1d261-9507-4ea7-b8c4-0dfc35506f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "res = []\n",
    "pops = ['AFR', 'EUR', 'EAS', 'SAS']\n",
    "for Nes in [1000, 10000]:\n",
    "    for p in pops:\n",
    "        for i in range(1, 101):\n",
    "            tmp = [Nes,p,m,i]\n",
    "            res.append(tmp)\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "df.to_csv(r\"/home/vsoni11/SF_realisations.txt\", header=False, index=False, sep='\\t')\n",
    "\n",
    "m = 2\n",
    "res = []\n",
    "pops = ['EUR', 'EAS', 'SAS']\n",
    "for Nes in [1000, 10000]:\n",
    "    for p in pops:\n",
    "        for i in range(1, 101):\n",
    "            tmp = [Nes,p,m,i]\n",
    "            res.append(tmp)\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "df.to_csv(r\"/home/vsoni11/SF_realisations.txt\", header=False, index=False, sep='\\t', mode='a')\n",
    "\n",
    "m = 3\n",
    "res = []\n",
    "pops = ['EUR']\n",
    "for Nes in [1000, 10000]:\n",
    "    for p in pops:\n",
    "        for i in range(1, 101):\n",
    "            tmp = [Nes,p,m,i]\n",
    "            res.append(tmp)\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "df.to_csv(r\"/home/vsoni11/SF_realisations.txt\", header=False, index=False, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736c48f-e7e7-4726-ae0d-6560ddbbfdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
